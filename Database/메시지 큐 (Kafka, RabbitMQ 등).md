# 메시지 큐 (Kafka, RabbitMQ 등) - 25.10.29

# 자 메시지 큐는 왜 생겼을까???

예전에는 웹 서비스가 굉장히 단순했음.

예를 들어 예전에 “회원가입” 요청을 처리할 땐 다음과 같았음.

1. 데이터베이스에 ID, PW 저장
2. 이메일 서비스 → 가입 축하 이메일 전송
3. 로그 시스템에 가입 로그 남기기
4. 통계 시스템에 +1 하기
- 중요한 것은, 이 모든 일을 “한 번의 요청 안에서 모두 처리 한다는 것”

**그래서 유저는 회원가입을 하면, 바로 로그인 해보길 기대하는 데, 이메일을 보내는 시간이 있다보니 응답속도가 느려져 유저의 기대를 져버리게 됨!**

그래서 “비동기 처리” 라는 개념이 도입 되었고, 이를 더욱 편하게 해주는 것이 “메시지 큐” 임.

# 그럼 메시지 큐는 어떤 역할을 하는 걸까?

아주 아주 간단하게 다음과 같음.

- 서버 A는 “이메일 보내줘”라는 메시지를 큐에 던져놓고,
- 바로 다음 일을 처리하러 가.
- 서버 B(이메일 서비스)는 시간이 될 때 큐에 쌓인 메시지를 하나씩 읽고 일을 처리해.

### 그래서 메시지 큐 에서는 다음과 같은 개념이 매우 중요함

- **Producer (생산자)**: 메시지를 큐에 넣는 주체 (서버 A)
- **Queue (큐)**: 메시지를 잠시 보관하는 중간 저장소
- **Consumer (소비자)**: 큐에서 메시지를 꺼내서 처리하는 주체 (서버 B)

이런 메시지 큐의 대표적인 예시로는 아래의 것들이 있음.

- RabbitMQ 🐇
- Kafka ⚙️
- AWS SQS ☁️
- Redis Streams 🔴 (가벼운 형태)

# 가장 대표적인 적용 예시

- **이메일/SMS 발송**
    
    → 메인 서버가 직접 발송하지 않고 큐에 요청을 남김.
    
    (사용자 응답은 바로 반환)
    
- **로그/트래픽 수집**
    
    → 서비스 요청마다 로그를 바로 DB에 저장하면 병목이 걸려.
    
    그래서 “로그 메시지”를 큐로 보내고,
    
    별도 소비자가 모아서 배치로 DB에 저장.
    
- **동영상 인코딩**
    
    → 사용자가 영상을 업로드하면 “인코딩 요청” 메시지를 큐에 넣고,
    
    백그라운드 작업 서버가 순서대로 처리.
    
- **주문 시스템**
    
    → 결제 요청, 주문 처리, 재고 차감, 포인트 적립 등 각 단계를 느슨하게 분리.
    

# 장단점은 뭘까?

## 메시지 큐의 장점

1. **비동기 처리 (Asynchronous Processing)**
    
    → 요청을 큐에 넣고 바로 응답 가능. 사용자 경험 ↑
    
2. **시스템 간 결합도 감소 (Decoupling)**
    
    → 서버 A와 B가 직접 통신하지 않아도 됨.
    
    서버 B가 잠깐 죽어도 큐가 메시지를 보관해줌.
    
3. **확장성 (Scalability)**
    
    → Consumer 서버를 여러 개 띄워서 병렬로 메시지를 처리할 수 있음.
    
4. **내결함성 (Fault Tolerance)**
    
    → 큐에 메시지가 남아 있으니, 장애 시에도 데이터 유실이 적음.
    

## 고려해야 할 리스크

1. **메시지 중복 처리**
    - Consumer가 처리 중 죽어버리면 같은 메시지가 다시 전달될 수 있어.
    - 그래서 **idempotent(멱등)**한 처리를 보장해야 함
        
        → “같은 메시지가 두 번 와도 결과가 같아야 한다.”
        
2. **메시지 순서 보장 문제**
    - 병렬로 처리하면 순서가 바뀔 수 있어.
    - 순서가 중요한 경우 “파티션”이나 “키 기반 정렬”을 고려해야 함.
3. **메시지 유실**
    - 큐 서버가 죽으면?
        
        → “acknowledgement(확인 응답)”과 “재시도 정책”이 중요함.
        
4. **지연 시간**
    - 즉시 처리되는 게 아니므로, 약간의 latency(지연)가 생김.
    - 실시간성이 중요한 서비스에는 부적합할 수 있음.

---

# 추가 내용 1 (메시지 큐의 동작 구체화)

## 🧩 상황 설정: 4가지 서버 인스턴스

```
[사용자]
   ↓ (HTTP 요청)
[Main Backend Server]
   ↓ (Kafka 메시지 발행)
[Kafka Broker Cluster]
   ↓ (메시지 구독)
[Email Service]
   ↓ (Kafka 메시지 발행)
[Log Service]

```

- **Main Backend Server** : 사용자 요청을 받는 메인 API 서버
- **Kafka Broker** : 메시지를 중간에서 전달하는 시스템 (“우체국”)
- **Email Service** : 이메일 발송 전용 마이크로서비스
- **Log Service** : 로그 수집/저장용 서비스

---

## ⚙️ 1단계: 사용자가 요청을 보냄

사용자가 “회원가입” 버튼을 누르면

→ `POST /api/signup` 같은 HTTP 요청이 **Main Backend Server**로 들어와.

```
POST /api/signup
{
  "email": "user123@example.com",
  "password": "abcd1234"
}

```

이제 서버는 해야 할 일이 많겠지:

1. DB에 사용자 정보 저장
2. 이메일 발송
3. 가입 로그 남기기

---

## 🚀 2단계: 카프카에 “메시지 발행 (Produce)”

메인 서버는 이메일을 직접 보내지 않고,

“이메일 요청 메시지”를 **Kafka의 특정 Topic**에 넣어.

### 코드 예시 (Java + Spring Kafka)

```java
EmailMessage msg = new EmailMessage("user123@example.com", "Welcome!", "가입을 환영합니다!");
kafkaTemplate.send("email-topic", msg);

```

여기서 `"email-topic"`은 일종의 **메일함 이름**이야.

즉, “이메일과 관련된 메시지는 다 여기로 넣자”는 약속이야.

이 시점에서 메인 서버는 더 이상 이메일 신경 안 써.

✅ 그냥 메시지만 남기고,

✅ 바로 사용자에게 `회원가입 완료` 응답을 반환해.

---

## 📦 3단계: Kafka가 메시지를 저장

Kafka는 단순히 “전달”만 하는 게 아니라,

메시지를 **디스크에 순서대로 저장**해.

```
[Kafka Broker]
 └── topic: email-topic
       ├── partition 0 → [msg1, msg2, msg3, ...]
       ├── partition 1 → [msg4, msg5, ...]

```

즉, 이건 “안 잊어버리는 우체국”.

누가 가져가기 전까지는 안전하게 메시지를 보관해줘.

---

## 📨 4단계: 이메일 서비스가 “구독 (Consume)”

이제 **Email Service**는 Kafka에서 “email-topic”을 **구독**하고 있어.

즉, “새로운 이메일 요청이 생기면 나한테 알려줘!”라고 등록해둔 상태야.

### 코드 예시 (Spring Kafka Consumer)

```java
@KafkaListener(topics = "email-topic", groupId = "email-service-group")
public void sendEmail(EmailMessage msg) {
    emailSender.send(msg); // 실제 이메일 발송
    kafkaTemplate.send("log-topic", new LogMessage("Email sent to " + msg.getTo()));
}

```

이 로직의 핵심은:

- Kafka가 email-topic에 메시지가 들어오면,
- EmailService의 `sendEmail()` 메서드를 자동으로 호출함.
- 이메일을 보낸 뒤, **또 다른 메시지 (log-topic)**를 발행해서 로그 서비스로 넘김.

---

## 🧮 5단계: 로그 서비스가 로그 메시지를 소비

이제 로그 서비스는 Kafka의 `"log-topic"`을 구독하고 있어.

```java
@KafkaListener(topics = "log-topic", groupId = "log-service-group")
public void saveLog(LogMessage log) {
    logRepository.save(log);
}

```

즉, 이메일 서비스는 “이메일을 보내는 역할”만 하고,

로그 서비스는 “기록하는 역할”만 하는 거야.

서로 몰라도 돼.

그냥 **Kafka라는 중간자**를 통해 메시지를 주고받을 뿐이야.

---

## 🔁 이렇게 흐른다 (요약)

```
1️⃣ [Main Server]
    회원가입 처리
    → Kafka(email-topic)에 "email 요청" 메시지 발행
    → 사용자 응답 반환

2️⃣ [Kafka Broker]
    메시지 저장

3️⃣ [Email Service]
    email-topic 구독
    → 이메일 발송
    → Kafka(log-topic)에 로그 메시지 발행

4️⃣ [Log Service]
    log-topic 구독
    → DB에 로그 저장

```

---

## 🌉 통신 구조 핵심 요약

| 구분 | 역할 | 프로토콜 | 통신 방향 |
| --- | --- | --- | --- |
| Main Server → Kafka | 메시지 발행 (Produce) | Kafka TCP 통신 (자체 프로토콜) | 단방향 |
| Kafka → Email Service | 메시지 구독 (Consume) | Kafka TCP 통신 | 단방향 |
| Email Service → Kafka | 메시지 발행 (Produce) | Kafka TCP 통신 | 단방향 |
| Kafka → Log Service | 메시지 구독 (Consume) | Kafka TCP 통신 | 단방향 |

→ 모든 통신은 **Kafka를 중심으로 비동기적 단방향 구조**로 이루어져.

HTTP 요청은 오직 “맨 처음 사용자 요청”에만 쓰이고,

그 뒤로는 **서버 간 HTTP 호출이 전혀 없다.**

---

## 💡 여기서 얻는 이점

1. **각 서비스가 서로를 모른다 (Decoupled)**
    
    → EmailService가 죽어도 MainServer는 전혀 영향 안 받음.
    
    (Kafka가 메시지를 대신 보관)
    
2. **확장성 (Scalability)**
    
    → EmailService 인스턴스를 10개 띄우면 Kafka가 메시지를 균등 분배함.
    
3. **내결함성 (Fault Tolerance)**
    
    → Consumer가 죽어도 나중에 다시 살아나면 Kafka가 안 읽은 메시지를 다시 전달.
    

---

## ⚠️ 하지만 이런 점을 고려해야 해

| 문제 | 설명 | 해결책 |
| --- | --- | --- |
| 중복 처리 | 같은 메시지를 여러 번 받을 수 있음 | Idempotent 설계 필요 |
| 메시지 순서 | 파티션 단위로만 순서 보장 | Key 기반 파티셔닝 |
| 메시지 유실 | Ack 누락, Consumer crash | Auto-offset commit, DLQ 설정 |
| 메시지 정체 | Consumer 처리 속도 느리면 큐가 꽉 참 | 모니터링 & 스케일 아웃 |

---

## 🔚 결론적으로

> 카프카는 **HTTP 요청 뒤에 이어지는 “비동기 통신 인프라”**야.
> 
> 
> 각 서비스들은 HTTP 대신 카프카 “토픽”을 통해 데이터를 주고받고,
> 
> 서로를 몰라도, 시스템은 전체적으로 **유기적으로 협력**한다.
> 

# 추가 내용 2 (메시지 큐 사용 시 데이터 일관성 문제, ex. JPA 영속성 컨텍스트, 트랜잭션 메시지 전송 문제)

“메시지 큐 좋아보이네?” 하고 실제로 마이크로서비스 구조 들어가면 바로 맞닥뜨리는 게 딱 그거야:

> 비동기 + 여러 인스턴스 + 각자 트랜잭션 → 데이터 일관성은 어떻게 보장할래?
> 

이걸 차근차근 풀어서 볼게. 우리가 지금 걱정하는 건 사실 한 단어로 요약돼: **분산된 시스템에서의 데이터 일관성(Consistency)**.

---

## 1. 우리가 겪게 되는 “진짜 문제” 상황 먼저 보자

상황을 좀 적나라하게 세팅해볼게.

### 장면

- Main 서버 인스턴스가 여러 개 떠 있어. (예: main-1, main-2)
- DB는 공용이야. (RDB 하나라고 하자)
- main-1에서 어떤 비즈니스 로직을 처리하면서 DB에 INSERT/UPDATE를 했고,
- 그 결과를 메시지로 카프카에 넣었어.
- 이메일 서비스나 다른 main-2 인스턴스는 그 메시지를 보고 뭔가 추가 작업을 해야 해.

여기서 문제가 뭐냐면:

1. main-1에서 트랜잭션이 아직 커밋되기 전인데,
    
    메시지는 이미 카프카로 나가버리면 어떡함?
    
    → Consumer 쪽(이메일 서비스)이 DB를 읽으려고 하면 아직 반영 안 되어 있을 수도 있음.
    
2. main-2는 같은 엔티티를 1차 캐시(EntityManager 컨텍스트)에 들고 있는데,
    
    main-1이 DB를 업데이트했다면
    
    main-2의 영속성 컨텍스트에는 오래된 값이 남아있을 수 있음.
    
    그리고 그 오래된 상태를 기준으로 추가 업데이트까지 하면?
    
    → 최종 상태 꼬일 수 있음.
    

이거 둘 다 맞는 걱정이야. 실제로 터지는 종류의 버그야.

이제 이걸 하나씩 해결하는 방식들을 볼게.

---

## 2. 문제 A: "DB 트랜잭션 vs 메시지 전송" 타이밍 문제

### 문제 요약

- 서비스 로직에서 DB에 뭔가 저장하고
- 그 사실을 알리려고 Kafka에 메시지를 보내는데
- 만약 DB 트랜잭션이 롤백됐는데, 메시지는 이미 발행됐다면?

→ 소비자(다른 서비스)는 “이거 완료된 거구나”라고 믿고 움직여버려.

근데 실제 DB에는 반영 안 됨.

= 데이터 불일치.

이걸 업계에서 뭐라고 하냐면

**“이중 쓰기(double write) 문제”**라고 해.

DB에도 쓰고, 메시지 브로커에도 쓰고 → 이 둘이 원자적(atomic)으로 안 묶여 있다는 게 핵심이야.

### 이 문제를 다루는 대표적인 패턴: “Outbox 패턴”

### 아이디어

1. 원래 비즈니스 테이블(예: `users`)만 업데이트하는 게 아니라
2. 같은 트랜잭션 안에서 `outbox`라는 별도 테이블에도 “전달할 메시지”를 같이 INSERT해.

즉, DB에 커밋이 일어날 때,

- 비즈니스 데이터
- 전송 예정 메시지
    
    이 둘이 동시에 커밋됨. “한 방에” 안정적으로 저장되는 거지.
    
1. 그리고 별도의 프로세스(혹은 스케줄러, 혹은 작은 전용 컨슈머)가 `outbox` 테이블을 계속 읽으면서 카프카에 실제 메시지를 전송하고, 전송된 건 `outbox`에서 처리 완료로 표시.

이 구조의 장점:

- 트랜잭션 롤백되면 outbox에도 안 들어가니까 메시지 자체가 안 나감 → 정합성 유지.
- 메시지는 DB에 안전하게 기록된 걸 기준으로 나가니까 “잃어버림”도 줄어듦.

정리하면:

- 서비스 로직: DB와 outbox까지만 신경
- 카프카 전송: 나중에 안전하게 별도로 수행

즉, 카프카 발행 자체가 메인 트랜잭션에 직접 끼지 않게 만드는 전략이야.

➡️ 이게 “트랜잭션과 메시지 발행을 어떻게 일치시키냐”에 대한 업계 표준 솔루션이라고 보면 돼. (특히 카프카 + RDB 조합일 때 정말 자주 쓴다)

---

## 3. 문제 B: “다른 서버 인스턴스의 1차 캐시(JPA 영속성 컨텍스트)가 오래된 값이면 어쩌지?”

너 이거도 되게 좋은 감각이야. 이건 “멀티 인스턴스 + JPA”로 가면 반드시 마주해.

상상해보자:

- main-1: `User(id=10)`의 status를 `ACTIVE`로 바꿔서 DB 커밋 완료
- main-2: 같은 `User(10)`을 이미 조회해놨고, 그 엔티티가 아직 영속성 컨텍스트에 살아있음 (JPA 1차 캐시)
- main-2에서 어떤 비즈니스 로직이 또 돌아가면서 `User(10)`을 수정하고 저장하면?
    
    → main-2 입장에선 “OLD 상태 기반 변경”이 DB에 덮어씌워질 수 있어.
    
    → 결국 main-1의 최신 변경이 날아갈 수도 있어. (Lost Update 문제)
    

이 문제는 사실 메시지 큐 때문이라기보다,

**동일한 데이터를 여러 인스턴스가 동시에 수정할 수 있게 된 순간 등장하는 분산 동시성 문제**야.

여기서 나오는 전형적인 대응책들이 있어.

---

### 대응책 1: 트랜잭션을 짧게 유지 + 요청 단위 EntityManager

스프링에서 보통 `@Transactional`은 “요청 하나 처리하고 끝날 때까지”를 단위로 하잖아.

그 말은:

- HTTP 요청마다 새로운 영속성 컨텍스트가 열리고
- 응답 직전에 flush & commit되고
- 컨텍스트는 버려진다 (닫힘)

즉, **요청 간에는 1차 캐시가 공유되지 않게 설계**하는 게 일반적이야.

(스프링 기본이 이 패턴이야)

그래서 보통은 “main-2가 10분 전의 엔티티 스냅샷을 들고 있다” 같은 상황은 잘 안 나와.

근데… “비동기 작업 스레드”나 “@Scheduled 작업” 등은 얘기가 달라져.

거긴 우리가 직접 트랜잭션 경계를 어떻게 가져가느냐에 따라 캐시 stale 문제가 생길 수 있어.

→ 결론: 비동기 Worker 쪽에서도 트랜잭션은 짧게, 매 처리마다 새로 열고 닫아라.

(Consumer 서비스 쪽에서는 보통 메시지 1건 처리할 때마다 별도 트랜잭션을 연다)

---

### 대응책 2: 낙관적 락(Optimistic Lock) / 버전 관리

엔티티에 `@Version` 필드를 두고 JPA의 낙관적 락을 활성화해.

이런 느낌:

```java
@Entity
class User {
    @Id
    Long id;

    String status;

    @Version
    Long version;
}

```

이렇게 하면 무슨 일이 생기냐면:

- main-1이 User(version=5)를 읽고 status=ACTIVE로 바꾼 뒤 저장 → version=6으로 증가
- main-2는 예전 상태(version=5)를 들고 있다가 뭔가 또 수정해서 저장하려 할 때,
    
    DB에는 이미 version=6이 있으니까 JPA가 예외(OptimisticLockException)를 던져버림
    

즉,

> “너 오래된 데이터를 기반으로 덮으려고 하네? 안 돼”
> 
> 
> 라고 시스템이 스스로 막아주는 거야.
> 

이건 분산 환경에서 **충돌 감지**를 위한 거의 필수 패턴이야.

---

### 대응책 3: 강제 리로드 / 캐시 무효화

만약 특정 데이터는 “항상 최신이어야만 한다”면,

- 매 요청마다 DB에서 다시 조회하도록 하고,
- 장시간 들고 있는 엔티티 레퍼런스를 신뢰하지 않는 방식으로 코딩해야 돼.

이건 실무 감각으로 말하면:

- “얘 자주 바뀌는 애니까, 서비스 내부에서 그냥 파라미터로 들고 다니지 말고 필요할 때마다 repository.findById로 다시 가져와라” 이런 식의 코드 스타일 가이드가 생겨.
- 혹은 Redis 같은 분산 캐시를 쓰면, update 시점에 캐시를 날리도록 합의하기도 하고.

---

## 4. 메시지 큐 비동기 구조에서 결국 생각해야 하는 것들

정리해보면, 비동기 + 분산 상태에서 생기는 대표 이슈는 이 세 가지야:

### (1) “쓰기 완료”가 진짜 완료인지?

- DB와 메시지 발행 사이 정합성
    
    → Outbox 패턴 같은 걸로 해결
    

### (2) 최신 상태를 누가 신뢰할 수 있는가?

- 여러 인스턴스가 같은 데이터를 다룰 때 갱신 충돌
    
    → 짧은 트랜잭션 단위, optimistic locking, 충돌 감지
    

### (3) 읽는 쪽 타이밍 문제

- Consumer가 메시지를 너무 빨리 처리해서, 아직 DB 커밋 안 된 데이터를 참조하려 할 수도 있음
    
    → 이건 보통 구조적으로 “커밋 이후에만 메시지가 나가게” (Outbox again) 하거나
    
    → consumer가 DB를 읽지 않고, 메시지 자체에 필요한 정보를 다 실어버리는 방식으로 줄이기도 해
    
    (예: “이 유저의 status는 ACTIVE다”라는 값을 메시지에 직접 넣어서, consumer가 굳이 DB를 다시 조회하지 않도록)
    

---

## 5. 한 문장으로 찍어줄게

- 단일 서버 + 단일 트랜잭션 시절엔 “DB에 넣었으면 끝”이었어.
- 근데 비동기/분산 구조로 가면
    
    “DB에 넣었다”
    
    “메시지를 발행했다”
    
    “다른 인스턴스가 그걸 읽고 뭔가 후속 작업을 했다”
    
    이 단계들이 전부 느슨하게 떨어져 있어서,
    
    **일관성(정합성)**은 이제 자동으로 보장되지 않는다.
    

그래서 생기는 필수 대응책이:

1. **Outbox 패턴** (DB 상태와 이벤트 발행의 원자성 확보)
2. **짧은 트랜잭션 경계 유지** (1차 캐시 오래 쥐고 있지 마)
3. **Optimistic Lock / 버전 관리**로 충돌 감지
4. (필요하면) 메시지에 “최종 상태 값”을 직접 넣어서 Consumer가 stale DB 읽지 않게 하기

---

---

## 추가 질문

“^무^”